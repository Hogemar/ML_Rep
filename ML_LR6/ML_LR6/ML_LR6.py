import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'# Устанавливаем уровень логирования TensorFlow на минимум, чтобы подавить ненужные сообщения
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist  # библиотека базы выборок Mnist
from tensorflow import keras
from tensorflow.keras.layers import Dense, Flatten


(x_train, y_train), (x_test, y_test) = mnist.load_data()

# стандартизация входных данных
x_train = x_train / 255
x_test = x_test / 255

'''
Преобразование меток тренировочных данных в категориальное кодирование "one-hot" – это процесс преобразования целочисленных меток 
в бинарное представление, где каждая метка представляется в виде вектора с одним активным (единичным) битом.

В данном случае, метки классов в базе данных MNIST представляют собой числа от 0 до 9, каждое из которых соответствует цифре на изображении. 
Процесс "one-hot" преобразования выглядит следующим образом:
1.Исходная метка: y_train[i] (где i - индекс тренировочного образца).

2.Создание вектора нулей длиной, равной количеству классов. В случае базы данных MNIST, где 10 классов (цифры от 0 до 9), вектор будет длиной 10.

3.Установка активного бита (1) в позицию, соответствующую исходной метке. Например, если y_train[i] равно 3, то устанавливаем третий элемент вектора в 1.
'''

#y_train_cat = keras.utils.to_categorical(y_train, 10)# Преобразование меток тренировочных данных в категориальное кодирование "one-hot"
#y_test_cat = keras.utils.to_categorical(y_test, 10)# Преобразование меток тестовых данных в категориальное кодирование "one-hot"
yes="Yes"
no="No"

y_train_last_digit_is_seven = np.array([yes if str(label)[-1] == '7' else no for label in y_train])
y_test_last_digit_is_seven = np.array([yes if str(label)[-1] == '7' else no for label in y_test])

'''
    Flatten(input_shape=(28, 28, 1)):
Этот слой предназначен для "выравнивания" (или "распрямления") входных данных. 
Исходные изображения в базе данных MNIST имеют размерность 28x28 пикселей. Однако перед подачей данных на слои с полносвязными нейронами (Dense), 
требуется преобразовать матрицу пикселей в одномерный вектор. Это достигается Flatten-слоем, который принимает входные данные размерности (28, 28, 1) и 
преобразует их в вектор длиной 28 * 28 * 1 = 784. Таким образом, он выравнивает двумерные данные в одномерный вектор.
'''
'''
    Dense(128, activation='relu'):
Это полносвязный (Dense) скрытый слой с 128 нейронами. 
Каждый нейрон в этом слое связан со всеми выходами предыдущего слоя (в данном случае, Flatten). 
Функция активации ReLU (Rectified Linear Unit) используется для введения нелинейности в выход каждого нейрона. 
ReLU активация возвращает 0 для всех отрицательных входов и само значение для всех неотрицательных входов. 
Это помогает сети изучать сложные нелинейные зависимости в данных.
'''
'''
   Dense(10, activation='softmax'):
Это выходной слой с 10 нейронами, соответствующими 10 классам в задаче классификации цифр от 0 до 9. 
Функция активации softmax используется здесь для преобразования выходов нейронов в вероятностные распределения.
 Softmax преобразует значения на выходе в диапазоне от 0 до 1 и обеспечивает, чтобы их сумма была равна 1. 
 Таким образом, результаты на выходе интерпретируются как вероятности принадлежности к каждому классу.
  Класс с наивысшей вероятностью выбирается как предсказание модели. 
'''
model = keras.Sequential([

    Flatten(input_shape=(28, 28, 1)), # Выравнивание входных данных

    Dense(128, activation='relu'),   # Скрытый слой с 128 нейронами и функцией активации ReLU

    #Dense(10, activation='softmax')  # Выходной слой с 10 нейронами (по числу классов) и функцией активации softmax
    Dense(1, activation='sigmoid')  # Изменено количество нейронов и функция активации
])


# настройка НС
'''
Этот код компилирует нейронную сеть, определяя ключевые параметры для обучения.Аргументы:
optimizer='adam': Оптимизатор, используемый для обновления весов сети. Adam - популярный метод оптимизации, сочетающий в себе идеи из методов адаптивного градиентного спуска.
loss='categorical_crossentropy': Функция потерь, используемая для измерения расхождения между предсказанными и фактическими значениями. В данном случае, это категориальная кросс-энтропия, часто применяемая в задачах классификации с несколькими классами.
metrics=['accuracy']: Метрика, используемая для оценки производительности модели во время обучения. Здесь используется точность (accuracy), которая измеряет долю правильных предсказаний.
'''
#model.compile(optimizer='adam',
#loss='categorical_crossentropy',# функция потерь = котегиральная кросс энтропия
 #             metrics=['accuracy'])

model.compile(optimizer='adam',
              loss='binary_crossentropy',  # Функция потерь для бинарной классификации
              metrics=['accuracy'])
'''
Этот метод обучает нейронную сеть на тренировочных данных.Аргументы:
x_train: Входные данные для обучения (нормализованные изображения цифр).
y_train_cat: Метки классов для обучения, преобразованные в категориальное кодирование "one-hot".
batch_size=32: Размер пакета (batch) данных, используемый при обучении. Градиенты вычисляются и обновляются после каждого пакета данных.
epochs=10: Количество эпох обучения. Эпоха представляет собой один проход через все тренировочные данные.
validation_split=0.2: Доля данных, выделенных для валидации. В данном случае, 20% тренировочных данных используются для валидации модели.
'''
#model.fit(x_train, y_train_cat, batch_size=32, epochs=10, validation_split=0.2)  # обучение НС

model.fit(x_train, (y_train_last_digit_is_seven == yes).astype(int), batch_size=32, epochs=10, validation_split=0.2)

# def digit_definition(res, option_number): # Определение функции для проверки совпадения результатов
#     if res == option_number:
#         return 1
#     else:
#         return 0

'''
Этот цикл используется для проверки первых 25 тестовых изображений 
и выводит предсказания модели вместе с изображениями и соответствующими метками.
'''
# count_numb = 25
# for n in range(count_numb):
#     x = np.expand_dims(x_test[n], axis=0)
#     res = model.predict(x)
#     print(res)
#     print('Результат: ' + str(
#         digit_definition(np.argmax(res), 3)))  # argmax возвращает индекс максимального значения вдоль указанной оси
#     plt.imshow(x_test[n], cmap=plt.cm.binary)
#     plt.show()
#     print()

count_numb = 20
for n in range(count_numb):
    x = np.expand_dims(x_test[n], axis=0)
    res = model.predict(x)
    print(res)
    predicted_label = yes if res >= 0.5 else no
    print('Is the last digit 7? ' + str(predicted_label))
    plt.imshow(x_test[n], cmap=plt.cm.binary)
    plt.show()
    print()

